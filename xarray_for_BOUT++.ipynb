{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# xarray + dask for BOUT++ data analysis \n",
    "\n",
    "## Readable, general, and scalable data analysis in python\n",
    "\n",
    "Thomas Nicholas\n",
    "\n",
    "(thomas.nicholas@york.ac.uk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What is xarray?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### xarray basic features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Analysing large datasets with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The xBOUT package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Suggestions for community tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multidimensional data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "All computational plasma physicists have some similar data analysis requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Relatively large datasets (up to 100's GBs)\n",
    "- Multidimensional\n",
    "- Warped-grid\n",
    "- Fluid turbulence\n",
    "- Visualise multiple dimensions easily\n",
    "- Apply mathematical operations over many dimensions easily and clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For BOUT++ we want standard library with all this + open source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is xarray?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "xarray is an open-source python library which provides Pandas-like labelling, visualisation & analysis functionality for N-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Developed by atmospheric physicists, who have similar data analysis needs to us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Already used extensively behind the scenes in OMFIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### xarray basic features: \n",
    "- Labelled multidimensional data\n",
    "- Clear syntax for operations\n",
    "- Lazy loading into memory\n",
    "- Plotting convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# xarray: Labelled multidimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "xarray wraps numpy arrays as \"variables\" and labels the dimensions.\n",
    "\n",
    "There can be multiple \"coordinates\" for the same data.\n",
    "\n",
    "Coordinates can be multidimensional\n",
    "(e.g. for mapping Orthogonal toroidal coordinates -> field-aligned coordinates)\n",
    "\n",
    "Multiple data variables are stored in same `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, imagine we had some output from an atmospheric fluid simulation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/dataset-diagram.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "<xarray.Dataset>\n",
    "Dimensions:        (t: 8, x: 8, y: 8)\n",
    "Coordinates:\n",
    "  * t              (t) int64 0 1 2 3 4 5 6 7 8\n",
    "  * x              (x) int64 0 1 2 3 4 5 6 7 8\n",
    "  * y              (y) int64 0 1 2 3 4 5 6 7 8\n",
    "    latitude       (x, y) float32 numpy.array(8, 8)\n",
    "    longitude      (x, y) float32 numpy.array(8, 8)\n",
    "Data variables:\n",
    "    temperature    (t, x, y) float32 numpy.array(8, 8, 8)\n",
    "    precipitation  (t, x, y) float32 numpy.array(8, 8, 8)\n",
    "Attributes:\n",
    "    reference_time 123.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Also carries around a dictionary of \"attributes\", which be used to store metadata as arbitary objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# xarray: Clear syntax for operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have some data $n(t,x,y,z)$, and we want to find the maximum over time of the spatially-averaged density at the separatrix. \n",
    "\n",
    "i.e. find $\\text{max}(<n(t,x=\\text{separatrix})>)$, where $<...>$ is an average over $y$ & $z$: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bare numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_separatrix_density = np.max(np.mean(n[:, sep_x, ...], axis=(2,3)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "xarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "max_separatrix_density = ds['n'].isel(x=sep_x).mean(dim=('y', 'z')).max(dim='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The xarray code is clearer, more generalisable, contains fewer \"magic numbers\", and the order of operations applied reads left-to-right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# xarray: Lazy loading into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "xarray uses the netCDF format in the backend.\n",
    "\n",
    "Lazily loads data values - never waste RAM on unneeded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Open a 100GB file\n",
    "ds = xr.open_dataset('BOUT_data.nc')\n",
    "\n",
    "# Select a 1GB subset of the data\n",
    "data = ds.isel(y=0)\n",
    "\n",
    "# Data is only loaded into memory here, when we actually need it\n",
    "result = some_maths(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# xarray: Plotting convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "xarray provides plotting functions which wrap matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Skip this in presentation because it just loads data\n",
    "from xbout import open_boutdataset\n",
    "\n",
    "ds = open_boutdataset('BOUT.dmp.*.nc')\n",
    "ds['x'].units = 'rho_s'\n",
    "ds['z'].units = 'rho_s'\n",
    "\n",
    "ds['phi'].units = 'V'\n",
    "ds['T'].units = 'eV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "drift_plane = ds['phi'].isel(t=-1, y=0)\n",
    "drift_plane.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# <img src=\"phi_2D_y=34.png\" alt=\"Drawing\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These plotting functions automatically use an appropriate type of plot for the dimension of the data (1D, 2D etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "profile = ds['T'].mean(dim=('t', 'y', 'z'))\n",
    "\n",
    "# Hide the creation of the new figure?\n",
    "fig, ax = plt.subplots()\n",
    "profile.plot.line(ax=ax)\n",
    "\n",
    "#plot_separatrix(data, sep_position, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# <img src=\"T_profile.png\" alt=\"Drawing\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "I've used this to write functions which plot 2D animated gifs which can animate over any dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.bout.animate2D(animate_over='t', x='x', y='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# ![tempgif](T_over_time.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# xarray + dask:\n",
    "\n",
    "- Memory chunking\n",
    "- Parallel analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you also install [dask](http://docs.dask.org/en/latest/install.html) (literally that's it, no other compiling or anything required), xarray will provide the option to load data into memory in chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### xarray + dask: Memory chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('example-data.nc', chunks={'time': 10})\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "<xarray.Dataset>\n",
    "Dimensions:      (latitude: 180, longitude: 360, time: 365)\n",
    "Coordinates:\n",
    "  * time         (time) datetime64[ns] 2015-01-01 2015-01-02 2015-01-03 ...\n",
    "  * longitude    (longitude) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ...\n",
    "  * latitude     (latitude) float64 89.5 88.5 87.5 86.5 85.5 84.5 83.5 82.5 ...\n",
    "Data variables:\n",
    "    temperature  (time, latitude, longitude) float64 dask.array<shape=(365, 180, 360), chunksize=(10, 180, 360)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now if you apply any xarray or any \"embarrassingly parallel\" numpy function to this dataset then it will compute the result only on one chunk at a time, and combine the results at the end.\n",
    "\n",
    "Useful when you have \"medium data\": larger than your RAM but smaller than your hard drive (so not \"big data\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### xarray + dask: Parallel analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "dask can also automatically parallelize the opertation of any xarray function, and most numpy and scipy functions, using the ``apply_ufunc`` helper function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xr.apply_ufunc(some_numpy_analysis_fn, ds, dask='parallelized', output=[float])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Chunking and parallelization through dask integration should allow you to easily scale up whatever analysis you were doing with numpy to work on datasets that are 100's of GBs in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The xBOUT package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[xBOUT](https://github.com/TomNicholas/xBOUT) aims to replace the pylib/boutdata tools which are currently in the BOUT++ repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Provides a simple interface for loading BOUT++ data as an xarray dataset efficiently from parallel simulation runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Stores the numerical data from the dump files, but also uses Ben's `BoutOptionsFile()` classes to store all simulation input in the attributes dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from xbout import open_boutdataset\n",
    "\n",
    "ds = open_boutdataset('BOUT.dmp.*.nc', inputfilepath='BOUT.inp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Data is stored lazily, and read in parallel using dask automatically.\n",
    "\n",
    "Faster than the current `boutdata.collect()` function (PROVE THIS)\n",
    "\n",
    "Core functionality implemented upstream in xarray ([Pull Request](https://github.com/pydata/xarray/pull/2553) waiting to be merged)\n",
    "\n",
    "Written using test-driven-development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Accessors\n",
    "\n",
    "Uses another feature of xarray - accessors - to provide BOUT-specific functionality as methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from xbout import open_boutdataset\n",
    "\n",
    "ds = open_boutdataset('BOUT.dmp.*.nc')\n",
    "\n",
    "ds.bout.to_restarts(savepath='.', nxpe=4, nype=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ds['n'].bout.animate2D(animate_over='t', x='x', y='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Package includes methods to perform common types of plasma turbulence data analysis (all parallelized using dask):\n",
    "\n",
    "(e.g. pdfs, ExB velocity, conditional averaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds['n'].bout.growth_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Subclassing for specific users\n",
    "\n",
    "Tools for general use in `xBOUT`, but `boutdataset` accessor allows subclassing for specific BOUT++ modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from xbout.boutdataset import open_boutdataset, BoutAccessor\n",
    "\n",
    "@register_dataset_accessor('storm')\n",
    "class StormAccessor(BoutAccessor):\n",
    "    \"\"\"\n",
    "    Class specifically for holding data from a simulation using the STORM module for BOUT++.\n",
    "    \"\"\"\n",
    "    def __init__(self, ds):\n",
    "        super().__init__(ds)\n",
    "\n",
    "    def plot_special_storm_plot()\n",
    "        print(\"STORM-specific functionality!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds = open_boutdataset('BOUT.dmp.*.nc')\n",
    "ds.storm.plot_special_storm_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Suggestions for BOUT++ community tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multidimensional coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Coordinates can be multidimensional\n",
    "\n",
    "Store mapping between (r,z,phi) -> Boozer coordinates as a 3D coord Boozer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Common plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ds['n'].bout.plot_poloidal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### More analysis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Growth rates, power spectra..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Staggered grids using xgcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Interesting work going on in the [xgcm](https://github.com/xgcm/xgcm) package \n",
    "\n",
    "xgcm (Xarray for Global Circulation Models) aims to provide objects which encode complex grids for use with xarray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can encode and perform operations on staggered grids:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/grid2d_hv.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Complex topologies using xgcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "xgcm can also encode complex topologies by storing connections between different cartesian grids:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/cubed_sphere.jpeg\" alt=\"Drawing\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Everyone who analyses multidimensional simulation data in python has similar needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Atmospheric physicists have already solved this problem for us: [xarray + dask](http://xarray.pydata.org/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Extendable API ideal for the varied BOUT++ community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Basic functionality already exists ([xBOUT](https://github.com/TomNicholas/xBOUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Potential for powerful common features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Blog post introducing xarray:\n",
    "http://stephanhoyer.com/2015/06/11/xray-dask-out-of-core-labeled-arrays/\n",
    "\n",
    "\n",
    "xarray GitHub:\n",
    "https://github.com/pydata/xarray/\n",
    "\n",
    "\n",
    "xarray documentation:\n",
    "http://xarray.pydata.org/en/stable/\n",
    "\n",
    "\n",
    "xarray documentation on dask integration:\n",
    "http://xarray.pydata.org/en/stable/dask.html\n",
    "\n",
    "\n",
    "Other useful blogs/tutorials:\n",
    "http://meteo.unican.es/work/xarray_seminar/xArray_seminar.html\n",
    "https://rabernat.github.io/research_computing/xarray.html\n",
    "\n",
    "\n",
    "Useful page from the dask documentation explaining the general idea:\n",
    "http://docs.dask.org/en/latest/delayed.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bonus: How does dask work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/collections-schedulers.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dask works by:\n",
    "    \n",
    "- Labelling the various operations you want to perform, using either dask objects like dask.arrays or encoding general functions using dask.delayed\n",
    "\n",
    "- Instead of evaluating these operations, it organises them into a Task Graph for later evaluation\n",
    "\n",
    "- Evaluates them using one of a set of Schedulers, which can perform in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "\n",
    "x = dask.delayed(inc)(1)\n",
    "y = dask.delayed(inc)(2)\n",
    "z = dask.delayed(add)(x, y)\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z.vizualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/inc-add.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
